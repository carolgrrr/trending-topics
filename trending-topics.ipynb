{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find trending topics on twitter for a list of locations and save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from TwitterAPI import TwitterAPI\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_twitter(config_file):\n",
    "    \"\"\" Read the config_file and construct an instance of TwitterAPI.\n",
    "    Args:\n",
    "      config_file ... A config file in ConfigParser format with Twitter credentials\n",
    "    Returns:\n",
    "      An instance of TwitterAPI.\n",
    "    \"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_file)\n",
    "    twitter = TwitterAPI(\n",
    "                   config.get('twitter', 'consumer_key'),\n",
    "                   config.get('twitter', 'consumer_secret'),\n",
    "                   config.get('twitter', 'access_token'),\n",
    "                   config.get('twitter', 'access_token_secret'))\n",
    "    return twitter\n",
    "\n",
    "def robust_request(twitter, resource, params, max_tries=5):\n",
    "    \"\"\" If a Twitter request fails, sleep for 15 minutes.\n",
    "    Do this at most max_tries times before quitting.\n",
    "    Args:\n",
    "      twitter .... A TwitterAPI object.\n",
    "      resource ... A resource string to request.\n",
    "      params ..... A parameter dictionary for the request.\n",
    "      max_tries .. The maximum number of tries to attempt.\n",
    "    Returns:\n",
    "      A TwitterResponse object, or None if failed.\n",
    "    \"\"\"\n",
    "    for i in range(max_tries):\n",
    "        request = twitter.request(resource, params)\n",
    "        if request.status_code == 200:\n",
    "            return request\n",
    "        else:\n",
    "            print('Got error:', request.text, '\\nsleeping for 15 minutes.', file=sys.stderr)\n",
    "            sys.stderr.flush()\n",
    "            time.sleep(61 * 15)\n",
    "\n",
    "def find_trends(twitter, location):\n",
    "    topics = robust_request(twitter, 'trends/place', {'id': location}, 20)\n",
    "    trends = []\n",
    "    for t in topics:\n",
    "        topic = \"%d\\t%s\\t%s\\t%s\\t%s\\t%s\\n\" %(location, t['name'], t['url'], str(t['tweet_volume']), t['promoted_content'], t['query'])\n",
    "        trends.append(topic)\n",
    "    return trends\n",
    "\n",
    "def find_place_ids(twitter):\n",
    "    places = robust_request(twitter, 'trends/available',{}, 20)\n",
    "    place_ids = []\n",
    "    for p in places:\n",
    "        place_ids.append(p['woeid'])\n",
    "    return place_ids\n",
    "\n",
    "def find_places(twitter):\n",
    "    places = robust_request(twitter, 'trends/available',{}, 20)\n",
    "    all_places = []\n",
    "    for p in places:\n",
    "        all_places.append(p)\n",
    "    return all_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitter = get_twitter('settings.cfg')\n",
    "print('Established Twitter connection.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "places = find_place_ids(twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_places = find_places(twitter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myid = 90036018\n",
    "for p in my_places:\n",
    "    if p['woeid'] == myid:\n",
    "        print(p['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('trending-topics-01-24-2016.csv', 'a') as tsv_file:\n",
    "    tsv_file.write('Location Name\\tWOE ID\\tName\\tURL\\tEvents\\tPromoted?\\tQuery\\n')\n",
    "\n",
    "# TODO - add headers\n",
    "#with open('topics.csv', 'w') as tsv_file:\n",
    "\n",
    "for place in places:\n",
    "    try:\n",
    "        trends = find_trends(twitter, place)\n",
    "        \n",
    "        for p in my_places:\n",
    "            if p['woeid'] == place:\n",
    "                name = p['name']\n",
    "        with open('trending-topics-01-24-2016.csv', 'a') as tsv_file:\n",
    "            #print(trends[0])\n",
    "            for topic in trends:\n",
    "                tsv_file.write(name+'\\t'+ topic)\n",
    "    except (Timeout, ssl.SSLError, ReadTimeoutError, ConnectionError) as exc:\n",
    "        print(\"error: %s\" % exc)\n",
    "        sleep(60*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Started at 8:31 PM. Failed, then restarted at 8:33 PM. Failed at 8:55 & restarted.\n",
    "\n",
    "Started at 10:58. Reached rate limit at 11:00\n",
    "Started at 12:49am. Failed at 3:10am (almost done)\n",
    "Started at 4:24am\n",
    "\n",
    "Started at 3PM 1/7. Done before 5PM (after 4:30 I think)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics_17 = []\n",
    "with open('trending-topics-01-24-2016.csv', 'r') as tsv_file:\n",
    "    for line in tsv_file:\n",
    "        row = line.split()\n",
    "        if '17' in row[2]:\n",
    "            topics_17.append(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(topics_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('trending-topics-17-01-24-2016.csv', 'w') as tsv_file:\n",
    "    for topic in topics_17:\n",
    "        row = \"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n\" %(topic[0], topic[1], topic[2], topic[3], topic[4], topic[5], topic[6])\n",
    "        tsv_file.write(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
